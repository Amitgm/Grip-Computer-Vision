{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social_distancing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name - Amit George**\n",
        "\n",
        "**Task 3 - Social Distancing detector** \n",
        "\n",
        "**Grip@ The Spark foundation network**\n",
        "\n",
        "**Objective- To detect social distancing between people within a certain crowd**"
      ],
      "metadata": {
        "id": "TH-yVCt1_6B-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the libraries**"
      ],
      "metadata": {
        "id": "IFgtF3aqecYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "import glob\n",
        "import shutil\n",
        "import torchvision\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "o6pSaA5c6IGZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model for detecting Person's**"
      ],
      "metadata": {
        "id": "CFwjV70C5W9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5x',\n",
        "                       pretrained=True, verbose=False)\n",
        "#model.cuda('cuda:0');"
      ],
      "metadata": {
        "id": "6pMpLLrFynbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading video-files from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JOoUTm0e1h6",
        "outputId": "8fad7a47-d427-4552-cb9a-30167879113d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir='/content/drive/MyDrive/video-files'\n",
        "images = natsorted(glob.glob(os.path.join(input_dir, '*.jpg')))"
      ],
      "metadata": {
        "id": "tRgkWygn2yGE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obtaining the bounding box coordinates of detected person's from the images** "
      ],
      "metadata": {
        "id": "EeYhban6dSv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=[]\n",
        "for img in images:\n",
        " image=cv2.imread(img)\n",
        " image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        " results = model([image[:, :, ::-1]])  # Pass the frame through the model and get the boxes\n",
        " results=results.xyxy[0].numpy()\n",
        " reults=results[results[:,5]==0] # only people\n",
        " data=results[:,:4] # take the first 4 bounding box corrdiates of pixels.\n",
        " dataset.append(data)"
      ],
      "metadata": {
        "id": "ZIPIvXMiyneI"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the centre distance between two persons's in the image**"
      ],
      "metadata": {
        "id": "CHBlem_Ddm3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def center_distance(xyxy1, xyxy2):\n",
        "    #Calculate the distance of the centers of the boxes.\n",
        "    a, b, c, d = xyxy1\n",
        "    x1 = int(np.mean([a, c]))\n",
        "    y1 = int(np.mean([b, d]))\n",
        "\n",
        "    e, f, g, h = xyxy2\n",
        "    x2 = int(np.mean([e, g]))\n",
        "    y2 = int(np.mean([f, h]))\n",
        "    \n",
        "    dist = np.linalg.norm([x1 - x2, y1 - y2])\n",
        "    return dist, x1, y1, x2, y2"
      ],
      "metadata": {
        "id": "x3bs10LNy3ZB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the social distance between people in the image, the red box means the person is close to the other person within 100 units and green box when far away from each other**"
      ],
      "metadata": {
        "id": "dun2TI5MdtlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list=[]\n",
        "distance=100\n",
        "for data,img in zip(dataset,images):\n",
        " image=cv2.imread(img)\n",
        " image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        " colors = ['green']*len(data)\n",
        " for i in range(len(data)):\n",
        "        for j in range(i+1, len(data)):\n",
        "            # Calculate distance of the centers\n",
        "            dist, x1, y1, x2, y2 = center_distance(data[i], data[j])\n",
        "            #distances.append(dist)\n",
        "            if dist < distance:\n",
        "                #distances.append(dist)\n",
        "                # If dist < distance, boxes are red and a line is drawn\n",
        "                colors[i] = 'red'\n",
        "                colors[j] = 'red'\n",
        "                image = cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "            for i, (x1, y1, x2, y2) in enumerate(data):\n",
        "                  # Draw the boxes\n",
        "                if colors[i] == 'green':\n",
        "                  color = (0, 255, 0)\n",
        "                else:\n",
        "                  color = (255, 0, 0)\n",
        "                image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        " image_list.append(image)\n",
        "        \n"
      ],
      "metadata": {
        "id": "tfgHGyldynl-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the object detection images to be later converted to video**"
      ],
      "metadata": {
        "id": "lm4QjswofGyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "for i,j in zip(image_list,images):\n",
        "  im = Image.fromarray(i)\n",
        "  im.save(\"/content/drive/MyDrive/social_distancing/{}.jpeg\".format(os.path.basename(j)))"
      ],
      "metadata": {
        "id": "KIiXb1ioKmX3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file for the data of images to be converted to video\n",
        "!zip -r '/content/social_distancing.zip' '/content/drive/MyDrive/social_distancing' "
      ],
      "metadata": {
        "id": "bgH-snngKmhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv '/content/drive/MyDrive/social_distance.mp4' '/content/'"
      ],
      "metadata": {
        "id": "sSfKdu8WdJ5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the video of social distancing**"
      ],
      "metadata": {
        "id": "ytKWUMRhc2X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path='/content/sample_data/social_distance.mp4'\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls><source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "metadata": {
        "id": "GBPsbdcUc5vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GH1ojBYuc1jc"
      }
    }
  ]
}