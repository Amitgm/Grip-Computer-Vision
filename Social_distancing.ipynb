{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social_distancing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNhp4r35hQLTA0tKFCoJQfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amitgm/Grip-Computer-Vision/blob/social_distancing/Social_distancing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name - Amit George**\n",
        "\n",
        "**Task 3 - Social Distancing detector** \n",
        "\n",
        "**Grip@ The Spark foundation network**\n",
        "\n",
        "**Objective- To detect social distancing between people within a certain crowd**"
      ],
      "metadata": {
        "id": "TH-yVCt1_6B-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the necessary libraries**"
      ],
      "metadata": {
        "id": "IFgtF3aqecYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "import glob\n",
        "import json\n",
        "import shutil\n",
        "from bs4 import BeautifulSoup\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "metadata": {
        "id": "o6pSaA5c6IGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model for detecting Person's**"
      ],
      "metadata": {
        "id": "CFwjV70C5W9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5x',\n",
        "                       pretrained=True, verbose=False)\n",
        "#model.cuda('cuda:0');"
      ],
      "metadata": {
        "id": "6pMpLLrFynbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading video-files from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4JOoUTm0e1h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dir='/content/drive/MyDrive/video-files'\n",
        "images = natsorted(glob.glob(os.path.join(input_dir, '*.jpg')))"
      ],
      "metadata": {
        "id": "tRgkWygn2yGE"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obtaining the bounding box coordinates of detected person's from the images** "
      ],
      "metadata": {
        "id": "EeYhban6dSv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=[]\n",
        "for img in images:\n",
        " image=cv2.imread(img)\n",
        " image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        " results = model([image[:, :, ::-1]])  # Pass the frame through the model and get the boxes\n",
        " results=results.xyxy[0].numpy()\n",
        " reults=results[results[:,5]==0] # only people\n",
        " data=results[:,:4] # take the first 4 bounding box corrdiates of pixels.\n",
        " dataset.append(data)"
      ],
      "metadata": {
        "id": "ZIPIvXMiyneI"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the centre distance between two persons's in the image**"
      ],
      "metadata": {
        "id": "CHBlem_Ddm3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def center_distance(xyxy1, xyxy2):\n",
        "    '''Calculate the distance of the centers of the boxes.'''\n",
        "    a, b, c, d = xyxy1\n",
        "    x1 = int(np.mean([a, c]))\n",
        "    y1 = int(np.mean([b, d]))\n",
        "\n",
        "    e, f, g, h = xyxy2\n",
        "    x2 = int(np.mean([e, g]))\n",
        "    y2 = int(np.mean([f, h]))\n",
        "    \n",
        "    dist = np.linalg.norm([x1 - x2, y1 - y2])\n",
        "    return dist, x1, y1, x2, y2"
      ],
      "metadata": {
        "id": "x3bs10LNy3ZB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the social distance between people in the image, the red box means the person is close to the other person within 100 units and green box when far away from each other**"
      ],
      "metadata": {
        "id": "dun2TI5MdtlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list=[]\n",
        "distance=100\n",
        "for data,img in zip(dataset,images):\n",
        " image=cv2.imread(img)\n",
        " image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        " colors = ['green']*len(data)\n",
        " for i in range(len(data)):\n",
        "        for j in range(i+1, len(data)):\n",
        "            # Calculate distance of the centers\n",
        "            dist, x1, y1, x2, y2 = center_distance(data[i], data[j])\n",
        "            #distances.append(dist)\n",
        "            if dist < distance:\n",
        "                #distances.append(dist)\n",
        "                # If dist < distance, boxes are red and a line is drawn\n",
        "                colors[i] = 'red'\n",
        "                colors[j] = 'red'\n",
        "                image = cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
        "\n",
        "            for i, (x1, y1, x2, y2) in enumerate(data):\n",
        "                  # Draw the boxes\n",
        "                if colors[i] == 'green':\n",
        "                  color = (0, 255, 0)\n",
        "                else:\n",
        "                  color = (255, 0, 0)\n",
        "                image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        " image_list.append(image)\n",
        "        \n"
      ],
      "metadata": {
        "id": "tfgHGyldynl-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the video of social distancing**"
      ],
      "metadata": {
        "id": "4qXI_tNrejDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_video(path):\n",
        "    '''Display video in Colab.'''\n",
        "    #compressed_path = path.split('.')[0]\n",
        "    #compressed_path = 'compressed_' + compressed_path + '.mp4'\n",
        "\n",
        "    if os.path.exists(path):\n",
        "        os.remove(path)\n",
        "\n",
        "    # Convert video\n",
        "    os.system(f\"ffmpeg -i {path} -vcodec libx264 {path}\")\n",
        "\n",
        "    # Show video\n",
        "    mp4 = open(path,'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(\"\"\"\n",
        "    <video width=400 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\n",
        "    \"\"\" % data_url)"
      ],
      "metadata": {
        "id": "j9retTCGzcBt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv '/content/drive/MyDrive/social_distance.mp4' '/content/'"
      ],
      "metadata": {
        "id": "-qup5wrI8QQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2='/content/'\n",
        "display_video(path2)"
      ],
      "metadata": {
        "id": "_qq5vUoHynpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the object detection images to be later converted to video**"
      ],
      "metadata": {
        "id": "lm4QjswofGyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "for i,j in zip(image_list,images):\n",
        "  im = Image.fromarray(i)\n",
        "  im.save(\"/content/drive/MyDrive/social_distancing/{}.jpeg\".format(os.path.basename(j)))"
      ],
      "metadata": {
        "id": "KIiXb1ioKmX3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file for the data of images to be converted to video\n",
        "!zip -r '/content/social_distancing.zip' '/content/drive/MyDrive/social_distancing' "
      ],
      "metadata": {
        "id": "bgH-snngKmhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8ZlgCDJU5TGZ"
      }
    }
  ]
}