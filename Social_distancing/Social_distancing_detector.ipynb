{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social_distancing_detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Name - Amit George**\n",
        "\n",
        "**Task 3 - Social Distancing detector** \n",
        "\n",
        "**Grip@ The Spark foundation network**\n",
        "\n",
        "**Objective- To detect social distancing between people within a certain crowd**"
      ],
      "metadata": {
        "id": "TH-yVCt1_6B-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the libraries**"
      ],
      "metadata": {
        "id": "IFgtF3aqecYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from natsort import natsorted\n",
        "from PIL import Image\n",
        "import glob\n",
        "import shutil\n",
        "import torchvision\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "o6pSaA5c6IGZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Model for detecting Person's**"
      ],
      "metadata": {
        "id": "CFwjV70C5W9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5x',\n",
        "                       pretrained=True, verbose=False)\n",
        "#model.cuda('cuda:0');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pMpLLrFynbE",
        "outputId": "fc877aed-7b4f-419f-f913-40ea529df45c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m PyYAML>=5.3.1 not found and is required by YOLOv5, attempting auto-update...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /root/.cache/torch/hub/ultralytics_yolov5_master/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 üöÄ 2022-6-18 Python-3.7.13 torch-1.11.0+cu113 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading video-files from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4JOoUTm0e1h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/sample_data/ezgif-4-a819b38007-jpg.zip' -d '/content/video-files'"
      ],
      "metadata": {
        "id": "IQaULj0HxQW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input_dir='/content/drive/MyDrive/video-files'\n",
        "input_dir= '/content/video-files'\n",
        "images = natsorted(glob.glob(os.path.join(input_dir, '*.jpg')))"
      ],
      "metadata": {
        "id": "tRgkWygn2yGE"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Obtaining the bounding box coordinates of detected person's from the images** "
      ],
      "metadata": {
        "id": "EeYhban6dSv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=[]\n",
        "for img in images:\n",
        " image=cv2.imread(img)\n",
        " image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        " results = model([image[:, :, ::-1]])  # Pass the frame through the model and get the boxes\n",
        " results=results.xyxy[0].numpy()\n",
        " results=results[results[:,5]==0] # only people\n",
        " data=results[:,:4] # take the first 4 bounding box corrdiates of pixels.\n",
        " dataset.append(data)"
      ],
      "metadata": {
        "id": "ZIPIvXMiyneI"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the centre distance between two persons's in the image**"
      ],
      "metadata": {
        "id": "CHBlem_Ddm3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def center_distance(xyxy1, xyxy2):\n",
        "    #Calculate the distance of the centers of the boxes.\n",
        "    a, b, c, d = xyxy1\n",
        "    x1 = int(np.mean([a, c]))\n",
        "    y1 = int(np.mean([b, d]))\n",
        "\n",
        "    e, f, g, h = xyxy2\n",
        "    x2 = int(np.mean([e, g]))\n",
        "    y2 = int(np.mean([f, h]))\n",
        "    \n",
        "    dist = np.linalg.norm([x1 - x2, y1 - y2])\n",
        "    return dist, x1, y1, x2, y2"
      ],
      "metadata": {
        "id": "x3bs10LNy3ZB"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate the social distance between people in the image, the red box means the person is close to the other person within 100 units and green box when far away from each other**"
      ],
      "metadata": {
        "id": "dun2TI5MdtlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list=[]\n",
        "for objects,img in zip(dataset,images):\n",
        " image=cv2.imread(img)\n",
        " image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        " for i, (x1, y1, x2, y2) in enumerate(objects):\n",
        "        color = (0, 255, 0)\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        " image_list.append(image)\n"
      ],
      "metadata": {
        "id": "E1P4CWvzE_U8"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_list2=[]\n",
        "distance=80 # or 60\n",
        "for objects,image in zip(dataset,image_list):\n",
        "  colors = ['green']*len(objects)\n",
        "  for i in range(len(objects)):\n",
        "        for j in range(len(objects)):\n",
        "            if i!=j:\n",
        "             print(i,j)\n",
        "             # Calculate distance of the centers\n",
        "             dist, cx1, cy1, cx2, cy2 = center_distance(objects[i], objects[j])\n",
        "             #distances.append(dist)\n",
        "             if dist < distance:\n",
        "                 x1,y1,x2,y2=objects[i]\n",
        "                 #distances.append(dist)\n",
        "                 # If dist < distance, boxes are red and a line is drawn\n",
        "                 color = (255, 0, 0)\n",
        "                 image = cv2.line(image, (cx1, cy1), (cx2, cy2), (0, 0, 255), 2)\n",
        "                 image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "                 break;\n",
        "  image_list2.append(image)              \n",
        "                \n"
      ],
      "metadata": {
        "id": "zQ7lXcNOH6x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/drive/MyDrive/social_distancing'"
      ],
      "metadata": {
        "id": "JNzyEIL22gSG"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the object detection images to be later converted to video**"
      ],
      "metadata": {
        "id": "lm4QjswofGyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "for i,j in zip(image_list2,images):\n",
        "  im = Image.fromarray(i)\n",
        "  im.save(\"/content/drive/MyDrive/social_distancing/{}.jpeg\".format(os.path.basename(j)))"
      ],
      "metadata": {
        "id": "KIiXb1ioKmX3"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip file for the data of images to be converted to video\n",
        "!zip -r '/content/social_distancing.zip' '/content/drive/MyDrive/social_distancing' "
      ],
      "metadata": {
        "id": "bgH-snngKmhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the video of social distancing**"
      ],
      "metadata": {
        "id": "ytKWUMRhc2X5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path='/content/sample_data/social_distance.mp4'\n",
        "mp4 = open(video_path, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=400 controls><source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "metadata": {
        "id": "GBPsbdcUc5vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GH1ojBYuc1jc"
      }
    }
  ]
}
